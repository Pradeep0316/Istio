###Install helm befor deploying Istio into your kbernetes cluster###
helm repo add istio.io https://storage.googleapis.com/istio-release/releases/1.4.0/charts/

###Search for istio packages by helm search istio###
helm search istio

###First install CRD by initializing the IStio and wait till the crds jobs complete##
helm install istio/istio-init --name istio-init --namespace istio-system
kubectl -n istio-system wait --for=condition=complete job --all

###Install Istio
helm install istio/istio --name istio --namespace istio-system

###To verify run below commands###
kubectl get svc -n istio-system
kubectl get pods -n istio-system

##Change the Isti0-ingressgateway by changing the type to NodePort
kubectl edit svc isto-ingressgateway  -n istio-system

###Install kiali dashboard to make clear view of traffic management ( It recieves all the metrics from Prometheous server)
helm fetch istio
cd istio/
helm install charts/templates/kiali --name helm-kiali --namespace istio-system --values values.yaml

###change the Kiali service to Nodeport from cluster Ip to access Kiali dashboard
kubectl edit svc kiali  -n istio-system

###Deploy sample application and test
helm search bookinfo
helm install bookinfo --name bookinfo 

###Traffic management
1. Traffic to Ingress gateway
2. From Ingress gateway to Gateway of your service
3. From gateway to Virtual service ( Destination details)


###Circuit breakers (Important part)###
By using Circuit breakers we wll make the system to more tolerant.
For Ex: Front end service is talking to backnd service for payments, during this if backend svc goes out of capacity, 
we will use circuit brakers to not send traffic to backend service for sometime to make that service settle down.
These are 3 types:
Closed: backend service is healthy, you can send requests
Half-open: Send few calls to check the status of back end, if yes please allow
Open: Back end service is not healthy, please stop sending requests to me


With these settings in the ConnectionPoolSettings field, only one connection can be made to the notifications service 
within a given time frame: one pending request with a maximum of one request per connection. If a threshold is reached, 
the circuit breaker will start tripping requests.

The OutlierDetection section is set so that it checks whether there is an error calling the service every second.
If there is, the service is ejected from the load balancing pool for at least three minutes
(the 100% maximum ejection percent indicates that all services can be ejected from the pool at the same time, if necessary).

The last line, “httpMaxRequestsPerConnection”, means that if a second connection is attempted against a container that 
already has an existing connection, the circuit will open. Because we’ve purposely made our container to mimic a slow service,
it will occasionally encounter this condition. When that happens, Istio will return a 503 error.

Ex:
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: notifications
spec:
  host: notifications
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 1
      http:
        http1MaxPendingRequests: 1
        maxRequestsPerConnection: 1
    outlierDetection:
      consecutiveErrors: 1
      interval: 1s
      baseEjectionTime: 3m
      maxEjectionPercent: 100
